---
title: 4. Linear Transformations
description: All about linear transformations.
authors: [Bhanu]
date: 2023-07-09
---

## What is a Linear Transformation
    We are now moving into some more applications of the basic concepts we spent lectures 1-3 learning. Good job on making it this far, stuff gets a little more interesting (and difficult) here.

    This whole lesson we will be learning linear transformations, which are one of the most important things in all of mathematics. Every single field uses linear transformations, and you've used linear transformations yourself without even realizing it.

## Linear Combinations & How They Relate
    Before we jump straight to linear transformations, lets take a baby step to linear combinations first. A linear combination is exactly what it sounds like: a way to combine vectors together linearly (addition/subtraction or multiplication).

    $$
    \begin{align*}
    3

    \begin{bmatrix}
    3 \\
    2 \\
    1 \\
    \end{bmatrix}
    - \frac{1}{2}
    \begin{bmatrix}
    -2 \\
    4 \\
    0 \\
    \end{bmatrix}
    =
    \begin{bmatrix}
    10 \\
    4 \\
    3 \\
    \end{bmatrix}
    \end{align*}
    $$

    This is an example of a __linear combination__, because 2 vectors are being combined by using scalar multiplication and addition. Now lets make this a little bit more complicated to start moving towards linear transformations.

    Lets consider a linear combination where the scalars are variables.

    $$
    \begin{align*}
    x_1

    \begin{bmatrix}
    -1 \\
    2 \\
    \end{bmatrix}
    + x_2
    \begin{bmatrix}
    3 \\
    1 \\
    \end{bmatrix}
     = 
    \begin{bmatrix}
    y_1 \\
    y_2 \\
    \end{bmatrix}
    \end{align*}
    $$

    We can clearly see that this is a linear combination where we take $$ x_1 $$ multiples of our first vector, and add $$ x_2 $$ multiples of our second vector to get some final vector with $$y_1$$ and $$y_2$$. But let's multiply this out and see what it looks like as a __system of equations__, like we saw in lecture 3.

    $$ 
    \begin{align}
    y_1 = -x_1 + 3x_2 \\
    y_2 = 2x_1 + x_2 \\
    \end{align}
    $$

    So we see now that systems of equations are analogous to linear combinations, and finding a solution for a system of equations is the same as finding coefficients to use in a linear combination to get some vector.

    Finally, lets connect this all to matrices, and then to linear transformations, which we will soon see are very closely related to matrices.

    Looking at the system of equations, we can also represent it now as the coefficient matrix, like this:

    $$ 
    \begin{align*}

    \begin{bmatrix}
    y_1\\
    y_2\\
    \end{bmatrix}
     = 
    \begin{bmatrix}
    -1 & 3 \\
    2 & 1 \\
    \end{bmatrix}
    \begin{bmatrix}
    x_1\\
    x_2\\
    \end{bmatrix}

    \end{align*}
    $$

    This is __very important!!!__ We now see that linear combinations are nothing more than a way to represent systems of equations, which in turn are a way to visualize matrix multiplication. But what is the underlying reasoning for all of this? __Linear Transformations!__

    We see from the matrix representation that all we are actually doing is taking some vector in $$\mathbb{R^2}$$, made up of $$ x_1 $$ and $$x_2$$, and multiplying it by a matrix in order to get a new vector in $$\mathbb{R^2}$$, made up of $$y_1$$ and $$y_2$$. It's now clear to see that the matrix we use _transforms_ the x vector into our new y vector. __We are using the matrix to apply a linear transformation to the vector.__ 
    
    This is the basic idea of what a linear transformation is, and we will get into its properties and impact next, but for now it is important to understand that vectors, matrices, systems of equations, and linear combinations all combine to give us this one concept of a linear transformation, and its __one of the most important parts of linear algebra__, so take your time to understand it.

## Linear Transformation

    Now lets get into how to actually talk about linear transformations. A linear transformation is a set of operations that takes us from a domain in $$\mathbb{R^n}$$ to a domain in $$\mathbb{R^m}$$. This means that it takes us from one dimension to another.
    If you remember from our section about matrices, this is the same definition we got for an application of matrices. We've finally gotten to that application, and so we now know that linear transformations can be represented as matrices. This is shown by saying "Linear transformation, T, given by the matrix A" where A will be some n x m matrix.

    Remember that a transformation takes us from one dimension to another, so a transformation represented by and n x m matrix takes us from $$\mathbb{R^m}$$ to $$\mathbb{R^n}$$. This makes sense because if we have a vector in $$\mathbb{R^2}$$ and we multiply it by a 3 x 2 matrix, we end up with a vector in $$\mathbb{R^3}$$:
    $$
    \begin{align*}
    \begin{bmatrix}
    1 & 1 \\
    0 & 2 \\
    -1 & 1 \\
    \end{bmatrix}
    \begin{bmatrix}
    -2 \\
    1 \\
    \end{bmatrix}
    =
    \begin{bmatrix}
    -1 \\
    2 \\
    3 \\
    \end{bmatrix}
    \end{align*}
    $$
    
## Linearity

## Inverse

## Injective

## Surjective

## Bijective

## Invertibility

## Why You Should Care

## Practice

